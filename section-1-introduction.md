# Section 1: Introduction

## Research Motivation: AI Transforming Workplace Autonomy

Artificial intelligence is fundamentally reshaping how work is organized, managed, and experienced. From algorithmic scheduling systems in warehouses to AI-driven performance monitoring in knowledge work, intelligent systems increasingly mediate the relationship between workers and their work. Recent institutional data reveals the scale of this transformation: 74% of firms in the United States now use software to automate managerial tasks, while 42.3% of European workers report working under algorithmic management systems (OECD 2025). Yet this technological shift raises profound philosophical questions that existing frameworks struggle to address: What happens to worker autonomy when algorithms assign tasks, monitor performance, and evaluate competence? How should we understand agency and control in work contexts increasingly shaped by opaque, data-driven systems?

These questions matter because autonomy—the capacity for self-governance and self-determination—has long been recognized as essential to human flourishing, moral responsibility, and dignity. Philosophical traditions from Kant (1785) to contemporary relational autonomy theorists (Mackenzie and Stoljar 2000; Lee 2023) emphasize that autonomy requires not just freedom from constraint but also supportive social conditions, access to information, and meaningful options. In workplace contexts specifically, empirical research across organizational psychology and sociology demonstrates that job autonomy predicts critical outcomes including job satisfaction, engagement, mental health, and performance (Humphrey et al. 2007; Van den Broeck et al. 2016). The Self-Determination Theory framework positions autonomy as a basic psychological need, on par with competence and relatedness (Ryan and Deci 2000). Workplace democracy advocates argue that if autonomy grounds political legitimacy, it should also ground economic governance (Dahl 1985; Anderson 2017).

Yet algorithmic management creates conditions that challenge core assumptions of these theories. Platform workers describe experiences of "algorithmic despotism" where systems minutely regulate time and activities while providing minimal information about how decisions are made (Griesbach et al. 2019). Information asymmetries between platforms and workers create what Lee et al. (2015) identify as fundamental barriers to autonomous decision-making—workers cannot make informed choices without understanding the systems governing their work. Opacity compounds control: when workers don't know how algorithms evaluate performance or allocate rewards, they lack the transparency many autonomy theories presume (Pasquale 2015; Ajunwa 2020). The scale and sophistication of data collection enable "surveillance capitalism" that treats workers as sources of behavioral data for extraction rather than agents deserving respect (Zuboff 2019).

## Why Existing Autonomy Concepts May Be Insufficient

This review argues that existing philosophical and empirical concepts of autonomy are insufficient for understanding and evaluating AI's workplace impacts. The insufficiency operates at multiple levels:

**Conceptual lag**: Dominant autonomy theories were developed without AI-mediated work in mind. Frankfurt's (1971) hierarchical model asks whether agents identify with their first-order desires through second-order volitions. Dworkin's (1988) procedural account focuses on whether identification processes are authentic rather than manipulated. But what does identification mean when algorithms shape which opportunities workers encounter, what information they receive, and how their performance is interpreted? These theories lack conceptual resources for addressing algorithmic opacity, data-driven personalization, and automated decision-making at scale.

**Measurement gaps**: Organizational psychology operationalizes autonomy through constructs like "work scheduling autonomy," "decision-making autonomy," and "work methods autonomy" (Morgeson and Humphrey 2006). These measures capture important dimensions but miss aspects specific to algorithmic management: autonomy over one's data, algorithmic transparency, and ability to contest automated decisions. The Job Characteristics Model (Hackman and Oldham 1976) treats autonomy as a stable job feature, but algorithmic systems can create dynamic, personalized experiences where autonomy varies within the same nominal job (Dubal 2023).

**Individual vs. relational tensions**: While relational autonomy theorists emphasize social constitution of agency (Westlund 2009; Friedman 2003), empirical workplace autonomy research remains largely individualistic. Yet algorithmic management reveals autonomy's fundamentally relational character: platform architectures distribute power asymmetrically, customer ratings mediate worker evaluation, and information asymmetries structure what workers can know and do (Curchod et al. 2020). Neither purely individualistic nor purely relational frameworks adequately capture these dynamics.

**Philosophical-empirical disconnect**: Philosophical autonomy debates rarely engage empirical findings about how workers actually experience and navigate algorithmic systems. Conversely, empirical research on algorithmic management often lacks philosophical sophistication about what autonomy requires and why it matters. This disconnect means philosophical theories risk irrelevance to actual workplace conditions, while empirical work lacks normative grounding for evaluation and critique.

## Structure of This Review

This review synthesizes philosophical, social scientific, and empirical literatures to map the state of knowledge about autonomy and AI-mediated work, identify critical gaps, and make the case for conceptual revision grounded in empirical investigation.

**Sections 2-3** establish philosophical foundations. Section 2 surveys general autonomy theories from classical accounts (Kant, Mill) through hierarchical models (Frankfurt, Dworkin) to contemporary relational approaches (Mackenzie and Stoljar, Westlund). Section 3 examines how philosophers have applied autonomy concepts specifically to work, including meaningful work theories (Veltman 2016; Cholbi 2022) and workplace democracy arguments (Anderson 2017; Frega et al. 2019). These sections establish conceptual baselines against which to evaluate AI's impacts.

**Section 4** presents social science perspectives on workplace autonomy, reviewing Self-Determination Theory (Gagné and Deci 2005), job design models (Hackman and Oldham 1980; Karasek 1979; Bakker and Demerouti 2007), job crafting and proactivity research (Wrzesniewski and Dutton 2001; Parker and Bindl 2017), and critical labor sociology (Braverman 1974; Kalleberg 2011). This section demonstrates robust empirical evidence for autonomy's importance while revealing measurement and conceptual limitations.

**Section 5** examines empirical methods for conceptual work, including experimental philosophy (Knobe and Nichols 2008), grounded theory for concept development (Charmaz 2014), and conceptual engineering approaches (Haslanger 2012; Burgess et al. 2020). These methodologies provide frameworks for empirically-informed concept revision.

**Sections 6-7** turn to AI's workplace impacts. Section 6 synthesizes empirical findings on algorithmic management frameworks (Kellogg et al. 2020), platform work conditions (Wood et al. 2019; Gray and Suri 2019), institutional data (OECD 2025; ILO 2024), and worker experiences. Section 7 examines critical political economy perspectives (Srnicek 2017; Zuboff 2019; Gandini 2019) and worker resistance strategies (Cini 2023; Cant 2019).

**Section 8** synthesizes key debates and theoretical tensions, including procedural vs. substantive autonomy in AI contexts, individual vs. relational autonomy under algorithmic management, and philosophical vs. empirical approaches to autonomy research.

**Section 9** identifies research gaps and argues for conceptual revision, showing how limitations in existing theories create need for empirically-grounded reconceptualization of workplace autonomy.

**Section 10** concludes by synthesizing findings and outlining paths forward for integrating philosophical rigor with empirical investigation.

## Research Questions Addressed

Throughout, this review addresses several interconnected questions:

1. **What do philosophical theories identify as necessary conditions for autonomy, and how might algorithmic management undermine these conditions?** Examining whether AI systems threaten autonomy requires clarity about what autonomy requires—a question philosophical theories directly address.

2. **How do social scientists operationalize and measure workplace autonomy, and what are the strengths and limitations of these approaches?** Understanding empirical methods and findings reveals what we know empirically about autonomy while identifying conceptual and measurement gaps.

3. **What empirical evidence exists about AI's impacts on worker autonomy, control, and agency?** Recent research on algorithmic management, platform work, and automation provides substantial evidence about how AI systems reshape work, though philosophical engagement with these findings remains limited.

4. **What tensions exist between philosophical and empirical approaches to autonomy, and how might they be productively integrated?** Philosophical sophistication without empirical grounding risks irrelevance; empirical research without normative frameworks lacks evaluative criteria. Integration requires methodological innovation.

5. **Why do existing autonomy concepts need revision to adequately address AI-mediated work?** Making the case for conceptual revision requires demonstrating that existing frameworks have systematic limitations that empirically-informed reconceptualization could address.

By integrating across disciplines and methods, this review establishes the intellectual foundation for empirical research aimed at revising autonomy concepts in light of AI's workplace transformations. The stakes are high: if autonomy is essential for human dignity, moral responsibility, and flourishing, understanding how algorithmic systems affect it becomes urgent. Yet without adequate concepts, we cannot clearly identify threats, evaluate interventions, or imagine alternatives. Conceptual work, empirically grounded, is thus not merely academic but practically and politically essential.

**Word count: ~1,050 words**
