# Section 6: AI's Impact on Workplace Autonomy: Empirical Findings

While philosophical and social science frameworks establish what autonomy is and why it matters, empirical research on algorithmic management reveals how AI systems actually affect worker autonomy, control, and agency in practice. Over the past decade, a substantial interdisciplinary literature has documented AI's workplace impacts through platform work studies, HCI research, institutional surveys, and critical ethnographies. This section synthesizes these findings, showing both how algorithmic management constrains autonomy and how workers develop strategies to navigate and resist algorithmic control.

## Algorithmic Management Frameworks: Conceptualizing AI Control

Kellogg, Valentine, and Christin's (2020) "Algorithms at Work" in *Academy of Management Annals* provides the foundational framework for understanding algorithmic management. Drawing on Edwards' contested terrain theory, they identify six mechanisms through which algorithms assume managerial functions—the "6 Rs" framework:

- **Restricting**: Algorithms limit options available to workers (Uber drivers can't see destination before accepting ride)
- **Recommending**: Algorithms suggest actions while preserving formal choice (Netflix recommendation algorithms, food delivery route suggestions)
- **Recording**: Algorithms continuously collect data on worker activities (keystroke monitoring, GPS tracking)
- **Rating**: Algorithms evaluate worker performance (customer ratings, productivity metrics)
- **Replacing**: Algorithms substitute for human decision-making (automated scheduling, task allocation)
- **Rewarding**: Algorithms determine compensation and incentives (dynamic pricing, gamification)

This framework reveals algorithmic management's multidimensionality—algorithms don't just control directly but shape work through information provision, evaluation, and reward structures. Importantly, algorithmic control can operate invisibly or indirectly, making it harder to recognize and contest than traditional hierarchical management.

Jarrahi et al. (2021) extend this framework with sociotechnical emphasis. They argue algorithmic management reflects both technological infrastructures and organizational choices—not technological determinism. Three key issues emerge: how algorithmic management reshapes power dynamics between workers and managers, how it demands new competencies while fostering opposition, and how it impacts knowledge exchange through opacity. Crucially, they demonstrate algorithmic management is spreading from platform gig economy to standard employment settings.

Lee et al.'s (2015) pioneering HCI study that coined "algorithmic management" examined Uber and Lyft, defining it as "software algorithms that assume managerial functions and surrounding institutional devices that support algorithms in practice." They identify information asymmetries as core problem—drivers cannot access information about how algorithms assign work, evaluate performance, or determine pay. Without understanding algorithmic logic, drivers struggle to make informed decisions about work strategies.

These frameworks establish several critical points: (1) Algorithmic management is not monolithic but operates through multiple mechanisms. (2) Control can be indirect—through information provision, evaluation structures, and incentive design—not just direct commands. (3) Opacity and information asymmetry are central features, not incidental bugs. (4) Algorithmic management is becoming mainstream, not confined to gig platforms.

## Platform Work and the Gig Economy: Evidence from the Field

Platform work provides the most extensively documented cases of algorithmic management. Wood et al.'s (2019) "Good Gig, Bad Gig" study of remote gig economy workers across six countries (107 interviews, N=679 survey) reveals autonomy paradoxes. Workers report high flexibility and autonomy over when and where to work, yet also experience low pay, social isolation, irregular hours, and exhaustion. The study challenges simple narratives—algorithmic management offers some autonomy dimensions (schedule flexibility) while constraining others (task control, information access). Non-proximity of workers and clients limits direct supervision, creating perceived autonomy despite algorithmic constraints.

Vallas and Schor's (2020) *Annual Review of Sociology* synthesis proposes platforms as "permissive potentates"—appearing to grant worker independence while exercising concentrated power. This captures platform paradox: workers are formally independent contractors yet face intense algorithmic management. Platforms externalize responsibility (workers bear risks, lack benefits) while centralizing control (algorithms direct, evaluate, discipline).

Rosenblat's (2018) *Uberland*, based on four years of ethnographic fieldwork riding with Uber drivers across 25+ cities, documents how Uber uses information asymmetries, customer rating surveillance, and behavioral nudges to manage drivers. Drivers experience unpredictability, gamification, and manipulation through algorithmic wage discrimination (different drivers see different pay for same ride) and surge pricing psychology. Rosenblat's work reveals platforms as traditional employers disguised as neutral marketplaces.

Gray and Suri's (2019) *Ghost Work*, a five-year study of crowdwork and Amazon Mechanical Turk, unveils invisible human labor making AI appear to work. "Ghost workers" perform high-tech piecework (content moderation, data labeling) with below-minimum wages, no benefits, and arbitrary termination ("rejections" where requesters don't pay for completed work). Workers are atomized, invisible, and excluded from labor protections. The book estimates 8% of Americans participate in this hidden economy essential for AI system functioning.

Griesbach et al.'s (2019) food delivery platform study (55 interviews, N=955 survey) documents variation in algorithmic control intensity. Instacart exerts "algorithmic despotism"—stringent regulation of time and activities through continuous monitoring and tight deadlines. Other platforms allow more discretion. This variation demonstrates that algorithmic control is not technologically determined but reflects design choices. Even within platform economy, significant variation exists in autonomy conditions.

Platform work research establishes: (1) Workers experience paradoxical autonomy—flexibility in some dimensions, constraint in others. (2) Information asymmetries systematically advantage platforms over workers. (3) Customer rating systems distribute managerial evaluation while making it difficult to contest. (4) Platforms achieve employer control without employer responsibilities through legal and technical structures. (5) Precarity and economic insecurity undermine effective autonomy even when formal choice exists.

## Institutional Data: Scale and Scope of Algorithmic Management

Recent institutional research documents algorithmic management's mainstream adoption. The OECD's (2025) first large-scale employer survey on algorithmic management surveyed 6,047 mid-level managers across six countries (France, Germany, Italy, Japan, Spain, United States). Findings reveal stunning adoption rates: 74% of U.S. firms use software to automate managerial tasks (instructing, monitoring, evaluating). Adoption reaches 90% in U.S., 79% average across European countries sampled.

Managers perceive improved decision quality but also report trustworthiness concerns: unclear accountability, inability to follow algorithmic logic, inadequate worker health protection. Worker surveys show reduced job satisfaction, increased workloads, stress, and job insecurity associated with algorithmic management. This institutional data demonstrates algorithmic management is not fringe phenomenon but mainstream practice affecting majority of workers in advanced economies.

The ILO's work documents global dimensions. Their 2024 report on "Algorithmic Management Practices in Regular Workplaces" examines Italy, France, India, and South Africa, finding algorithmic management spreading beyond gig economy into traditional employment. The 2023 generative AI analysis (Gmyrek et al.) develops task-based methodology showing 25% of jobs face significant AI exposure. Crucially, they find augmentation more likely than full automation but significant gender and geographic disparities—women and developing-country workers more vulnerable to automating effects.

Berg et al.'s (2018) ILO survey of 3,500 crowdworkers across 75 countries on five major platforms documents global platform work conditions: low pay (often below minimum wage), unpredictable income, no social protection, high rejection rates, poor worker-client communication. Decent work deficits are substantial and systematic, not incidental. Platform architectures create these conditions structurally.

Institutional data confirms: (1) Algorithmic management affects majority of workers in advanced economies. (2) Adoption extends far beyond platform gig work to traditional employment. (3) Global scope includes both developed and developing economies, with inequality in impacts. (4) Worker well-being costs are measurable—reduced satisfaction, increased stress, greater insecurity. (5) Governance gaps exist around accountability, transparency, health protection.

## Worker Experiences and Responses: HCI and Sociotechnical Research

HCI research provides rich qualitative data on how workers experience and navigate algorithmic systems. Irani and Silberman's (2013) Turkopticon study (Best Paper at CHI 2013) analyzes Amazon Mechanical Turk as site where human computation relies on worker invisibility. Turkopticon is an activist browser extension enabling workers to publicize and evaluate relationships with requesters by inserting reviews into AMT's interface. Workers use it to share information, hold requesters accountable, and make visible power asymmetries built into platform architecture. The system demonstrates workers actively reshaping information environments despite platform constraints.

Salehi, Irani, and Bernstein's (2015) "We Are Dynamo" (CHI Honorable Mention) presents first socio-technical system supporting collective action for crowd workers. Dynamo enabled Mechanical Turk workers to collaboratively author ethical research guidelines and organize campaigns. Despite geographic dispersion and platform atomization, workers organized for better treatment. This proves worker agency and collective action are possible even under individualizing platform architectures.

Curchod et al.'s (2020) study of 77 high-performing eBay sellers in France and Belgium develops grounded theory of power asymmetries in online work. Customer evaluations create novel power dynamics where workers navigate both platform algorithms and customer assessments. Despite structural constraints and information asymmetries, workers develop agency through understanding and strategically engaging algorithmic systems.

Möhlmann et al.'s (2021) analysis of Uber distinguishes algorithmic management's matching function (connecting workers with tasks) from control function (monitoring and regulating). While matching receives attention, platforms also use algorithms for tight surveillance and manipulation. Driver interviews reveal perceived benefits (income opportunities) and constraints (surveillance, information gaps). This dual nature—coordination plus control—reflects broader tensions in platform design.

Sutherland and Jarrahi's (2019) Upwork study demonstrates workers develop "algorithmic competencies"—literacy for understanding algorithms despite information asymmetries. Three strategies emerge: sensemaking (understanding platform logic), circumventing (working around constraints), and manipulating (gaming systems to retain autonomy). Workers are not passive recipients but develop knowledge to maintain professional autonomy despite platform control. This reveals agency as actively achieved through effort, not passively given.

HCI research shows: (1) Workers experience algorithmic systems as simultaneously enabling and constraining. (2) Information asymmetry and opacity are central grievances. (3) Workers develop tools (Turkopticon), organize collectively (Dynamo), and cultivate algorithmic competencies to navigate constraints. (4) Agency persists but requires active effort and strategic navigation. (5) Visibility/invisibility affects both worker recognition and accountability.

## Beyond Platforms: AI in Traditional Workplaces

Increasingly, research examines algorithmic management in conventional employment beyond gig platforms. Delfanti's (2021) warehouse research, combining patent analysis with ethnographic observation, reveals Amazon's vision of "humanly extended automation" where humans and robots are intimately integrated with both managed by algorithmic systems. Patents portray machines increasing worker surveillance and work rhythms while incorporating workers' activities into machinery for "digital Taylorism." Automation reshapes rather than eliminates human work, intensifying pace and control.

Ajunwa's (2020, 2021) legal scholarship examines algorithmic hiring and workplace monitoring as "black boxes" lacking transparency and accountability. Digital discrimination affects millions who often don't know they're algorithmically assessed. Opacity prevents workers from understanding, contesting, or correcting automated decisions. Ajunwa advocates auditing requirements and transparency safeguards, informing Congressional testimony and policy debates.

The OECD (2025) data on algorithmic management in traditional employment shows adoption across sectors: manufacturing, logistics, services, knowledge work. Not just physical labor but professional work increasingly involves algorithmic evaluation, task assignment, and performance monitoring. European Working Conditions Survey (2024) finds 42.3% of EU workers report algorithmic management.

Krzywdzinski's (2021) automotive industry analysis (1990s-2018) across US, Germany, and Japan questions automation employment threat narratives. Despite heavy robotization, production employment persists. Automation doesn't uniformly eliminate jobs but reshapes occupational composition differently across national contexts. Social choices about automation implementation matter—not technological determinism.

Research on traditional workplace AI reveals: (1) Algorithmic management extends across sectors and occupation types. (2) Digital Taylorism—fragmentation, intensification, tight control—characterizes some implementations. (3) Hiring algorithms create discrimination risks often invisible to applicants. (4) Even professional knowledge work increasingly faces algorithmic evaluation and monitoring. (5) Implementation varies by organizational choice and national context, not just technology.

## Synthesis: Empirical Patterns in AI's Autonomy Impacts

Across platform work, traditional employment, global contexts, and sectors, several empirical patterns emerge:

**Information asymmetry is systematic**: Workers consistently lack information about how algorithms assign work, evaluate performance, set pay, and make decisions affecting them. This is not incidental but architected into systems.

**Autonomy is paradoxical**: Workers experience increased autonomy in some dimensions (schedule flexibility, location independence) while facing decreased autonomy in others (task control, methods, contestation of decisions). Simple increase/decrease framing misses multidimensionality.

**Control becomes indirect**: Algorithms control not just through direct commands but through information provision, evaluation structures, behavioral nudges, and economic incentives. This indirect control can be harder to recognize and contest than traditional supervision.

**Worker agency persists**: Despite constraints, workers develop algorithmic competencies, organize collectively, create counter-technologies (Turkopticon), and craft work within algorithmic systems. Agency is active achievement, not passive receipt.

**Impacts are unequal**: Algorithmic management affects workers differently by occupation, sector, geography, race, gender, and immigration status. Inequality in autonomy access and exposure to algorithmic control is substantial and structured.

**Scale is significant**: Majority of workers in advanced economies now work under some form of algorithmic management. This is mainstream phenomenon affecting labor markets broadly, not confined to tech sector or gig platforms.

**Governance gaps exist**: Legal frameworks (employment classification, privacy, discrimination law) and organizational practices (transparency, accountability, worker voice) lag behind technological deployment. Workers lack adequate protections and recourse.

These empirical findings establish that AI's workplace impacts are neither uniformly positive (techno-optimist augmentation) nor uniformly negative (techno-pessimist displacement). Instead, algorithmic management creates new configurations of autonomy and control, with effects varying by design choices, organizational contexts, regulatory frameworks, and worker responses. Understanding these impacts requires attention to specifics—which autonomy dimensions, for which workers, under what conditions?

Importantly, empirical research demonstrates that existing autonomy frameworks—both philosophical and social scientific—were not developed with these specific conditions in mind. Information asymmetry at this scale, indirect algorithmic control, continuous surveillance and data collection, personalized algorithmic treatment, and opacity about decision logic represent conditions that challenge conceptual adequacy of traditional autonomy theories. The empirical evidence makes a strong case that conceptual work is needed—not just applying existing frameworks but potentially revising them to adequately capture what's at stake in algorithmically mediated work.

**Word count: ~2,000 words**
