@comment{===================================================================}
@comment{DOMAIN 4: EPISTEMIC INJUSTICE AND AI}
@comment{===================================================================}
@comment{
Domain Focus: This domain examines how AI systems perpetuate, mitigate,
or create new forms of epistemic injustice. Key themes include:
testimonial injustice in AI systems, hermeneutical injustice and
algorithmic bias, credibility excess/deficit in AI testimony, power
dynamics in AI-mediated belief revision, and democratic implications
of AI-driven epistemic stratification.

Search Strategy: PhilPapers (epistemic injustice + AI, algorithmic bias
+ epistemology), Ethics and Information Technology, Philosophy &
Technology, feminist philosophy of AI, ACM FAT/FAccT conferences

Key Questions:
- Can AI systems perpetuate or mitigate epistemic injustice?
- How do power dynamics affect AI-mediated belief revision?
- What is credibility excess vs. deficit in AI testimony?
- What are democratic implications of AI-driven belief shifts?
}
@comment{===================================================================}

@inproceedings{Kay2024Generative,
  author = {Kay, Jackie and Kasirzadeh, Atoosa and Mohamed, Shakir},
  title = {Epistemic Injustice in Generative AI},
  booktitle = {Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  year = {2024},
  volume = {7},
  number = {1},
  pages = {684--697},
  doi = {10.1609/aies.v7i1.31671},
  url = {https://arxiv.org/abs/2408.11441},
  note = {Major paper investigating how generative AI can undermine integrity of collective knowledge. Introduces concept of generative algorithmic epistemic injustice. Identifies four dimensions: amplified and manipulative testimonial injustice, hermeneutical ignorance and access injustice. Real-world examples in multilingual contexts. ArXiv preprint 2408.11441.}
}

@article{Milano2024Profiling,
  author = {Milano, Silvia and Prunkl, Carina},
  title = {Algorithmic Profiling as a Source of Hermeneutical Injustice},
  journal = {Philosophical Studies},
  year = {2024},
  volume = {182},
  number = {1},
  pages = {185--203},
  doi = {10.1007/s11098-023-02095-2},
  url = {https://link.springer.com/article/10.1007/s11098-023-02095-2},
  note = {Shows how algorithmic profiling can give rise to epistemic injustice through depletion of epistemic resources needed to interpret and evaluate certain experiences. Introduces novel concept of 'epistemic fragmentation' as source of hermeneutical injustice. Open access, published February 2024.}
}

@article{AustralianFS2025Gendered,
  title = {The Gendered, Epistemic Injustices of Generative AI},
  journal = {Australian Feminist Studies},
  year = {2025},
  volume = {40},
  number = {123},
  doi = {10.1080/08164649.2025.2480927},
  url = {https://www.tandfonline.com/doi/full/10.1080/08164649.2025.2480927},
  note = {Studies identify 'generative epistemic injustice' with elements like generative hermeneutical ignorance, in which systems can erase or misportray marginalized groups through 'interpretive misrecognition'. Gender-biased GenAI responses in leadership and workplace contexts reinforce stereotypes, leading to offline injustices.}
}

@inproceedings{ACM2025Civil,
  title = {Epistemic Injustice in Algorithmic Systems and the Limits of Civil Rights Law},
  booktitle = {Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency},
  year = {2025},
  doi = {10.1145/3715275.3732213},
  url = {https://dl.acm.org/doi/10.1145/3715275.3732213},
  note = {Research documents epistemic injustice in child welfare systems targeting Black communities, healthcare opioid risk predictions showing 'automated hermeneutical appropriation', and COMPAS recidivism algorithms committing hermeneutical injustice through biased classifications. Legal and technical analysis. Emerging field named 'algorithmic epistemic injustice' (Byrnes & Spear 2023).}
}

@article{PhilTech2025Harm,
  title = {AI's Epistemic Harm: Reinforcement Learning, Collective Bias, and the New AI Culture War},
  journal = {Philosophy \& Technology},
  year = {2025},
  volume = {38},
  doi = {10.1007/s13347-025-00928-y},
  url = {https://link.springer.com/article/10.1007/s13347-025-00928-y},
  note = {Examines epistemic harm from AI systems through reinforcement learning and collective bias. Positions AI epistemic issues within broader culture war dynamics. Shows how technical choices in AI design perpetuate epistemic injustices at population level.}
}

@article{AISociety2024Medical,
  author = {Authors, Multiple},
  title = {From Ethics to Epistemology and Back Again: Informativeness and Epistemic Injustice in Explanatory Medical Machine Learning},
  journal = {AI \& Society},
  year = {2024},
  doi = {10.1007/s00146-024-01875-6},
  url = {https://link.springer.com/article/10.1007/s00146-024-01875-6},
  note = {Medical AI context. Shows how lack of informativeness in ML explanations can constitute epistemic injustice for both patients and clinicians. Bridges ethics and epistemology of AI in healthcare. Explanatory AI and epistemic justice.}
}

@inproceedings{ACM2024Knowledge,
  title = {Knowledge-Enhanced Language Models Are Not Bias-Proof: Situated Knowledge and Epistemic Injustice in AI},
  booktitle = {Proceedings of the ACM Conference},
  year = {2024},
  doi = {10.1145/3630106.3658981},
  url = {https://dl.acm.org/doi/fullHtml/10.1145/3630106.3658981},
  note = {Knowledge enhancement is at risk of perpetuating epistemic injustice. AI engineers' understanding of knowledge as objective per se conceals this injustice. Shows that even knowledge-enhanced LLMs perpetuate biases. Situated knowledge perspective on AI epistemology.}
}

@incollection{Wiley2024Companion,
  title = {AI and Epistemic Injustice},
  booktitle = {A Companion to Applied Philosophy of AI},
  publisher = {Wiley},
  year = {2024},
  doi = {10.1002/9781394238651.ch9},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/9781394238651.ch9},
  note = {Book chapter providing comprehensive overview of AI and epistemic injustice. Synthesizes emerging literature on algorithmic epistemic injustice. Companion volume chapter - authoritative reference.}
}

@article{PMC2024Biases,
  title = {Biases in AI: Acknowledging and Addressing the Inevitable Ethical Issues},
  journal = {PMC},
  year = {2024},
  url = {https://pmc.ncbi.nlm.nih.gov/articles/PMC12405166/},
  note = {Medical and bioethics perspective on AI bias with epistemic dimensions. Acknowledges biases as inevitable, focuses on strategies for addressing them. Cross-disciplinary approach to epistemic injustice in AI systems.}
}

@article{PhilArchive2023Inquiry,
  title = {A Philosophical Inquiry into AI-Inclusive Epistemology},
  author = {You, TBD},
  journal = {PhilArchive},
  year = {2023},
  url = {https://philarchive.org/archive/YOUAPI-3},
  note = {Discusses distributed epistemic agency and accountability. What qualifies system as epistemic is capacity to generate, justify, and revise knowledge claims in verifiable, accountable, and contestable way. Contestability essential for avoiding epistemic injustice.}
}
