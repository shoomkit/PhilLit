## Epistemic Agency and Authority: The Core Conceptual Debate

Contemporary philosophical work on AI and epistemic agency centers on a fundamental question: when AI systems influence belief formation, do they extend, transform, or displace human epistemic agency? Recent scholarship reveals deep disagreements about AI's proper epistemic role—whether as tool, partner, or authority—with significant implications for how we understand rationally-mediated belief revision.

### Defining Epistemic Agency in the AI Age

Epistemic agency traditionally refers to the capacity for autonomous belief formation through one's own cognitive and evidential engagement. Yet AI systems complicate this picture by introducing what Coeckelbergh (2025) calls "technology-based belief," where "non-human agency can function as the originator of our beliefs and their content" (Coeckelbergh 2025, 5). This differs fundamentally from testimony-based belief (where humans vouch for claims) and instrument-based belief (where tools extend but don't originate reasoning). The question becomes whether technology-based beliefs are compatible with epistemic agency or represent a form of epistemic displacement.

Coeckelbergh argues for the pessimistic view: AI use "risks to influence the formation and revision of our beliefs in ways that diminish our epistemic agency" (Coeckelbergh 2025, 1). The concern is not merely about false information or bias, but about the structural relationship between human reasoners and AI systems. When AI systems shape the informational landscape, select relevant evidence, and frame interpretive possibilities, they may constrain rather than enable autonomous epistemic engagement—even when the information provided is accurate and the user critically evaluates it.

In contrast, Naeem and Hauser (2024) defend the possibility of epistemically responsible AI extension. They distinguish between "phenomenally transparent" AI use (where users experience AI outputs as their own beliefs) and "epistemically integrated" AI use (where users remain responsive to the reliability of AI processes). On their view, "when agents are responsive to the reliability of their AI processes through epistemic integration, beliefs formed responsibly and transparent AI extension is possible" (Naeem & Hauser 2024, 91). This framework suggests that epistemic agency is compatible with AI assistance provided users maintain appropriate epistemic vigilance about AI reliability.

Wu et al. (2025) propose a third model: "shared epistemic agency" between humans and generative AI systems. Rather than viewing agency as a zero-sum resource that AI either preserves or displaces, they advocate for "a symbiotic relationship where both human and machine contributions are valued" (Wu et al. 2025). This educational framework suggests that epistemic agency might be distributed across human-AI systems rather than residing solely in individual human cognizers. Whether this constitutes genuine agency or a dissolution of the concept remains philosophically contested.

### AI as Epistemic Authority or Epistemic Tool?

A parallel debate concerns whether AI systems can legitimately serve as epistemic authorities. Hauswald (2025) examines this question systematically, asking "whether ChatGPT could serve as a good teacher and whether it should be recognized as an 'artificial epistemic authority'" (Hauswald 2025, 716). Recognizing AI as an epistemic authority would mean treating its outputs as providing reason to believe something not merely because the outputs are reliably produced, but because the system itself warrants epistemic deference.

Koskinen (2023) argues against this possibility on structural grounds: "Scientists are now epistemically dependent on AI applications that are not agents, and therefore not appropriate candidates for trust" (Koskinen 2023, 2). On this view, epistemic authority requires the kind of moral and rational answerability that only agents possess. AI systems may be reliable without being authoritative; we can depend on their outputs while recognizing they cannot provide the kind of testimony or warrant that constitutes genuine epistemic authority.

Yet recent work on "algorithmic truth" suggests AI systems increasingly function as de facto epistemic authorities regardless of their philosophical status. According to research in AI & Society, "LLMs are increasingly treated as epistemic authorities, with users regarding them as credible sources of knowledge" and "scholars have accepted AI as an epistemic authority for providing truth indicators, scientific predictions, and reliable outputs" (AI & Society 2025). This descriptive reality creates tension with normative frameworks that would restrict epistemic authority to moral agents.

Sahebi and Formosa (2025) identify the resulting dilemma: AI-mediated communication "poses a risk to epistemic trust being diminished on both normative and descriptive grounds" (Sahebi & Formosa 2025). Normatively, AI lacks the features (intentionality, answerability, moral responsibility) traditionally grounding epistemic trust. Descriptively, users increasingly extend trust to AI systems, creating potential for what they term "epistemic passivity"—diminished responsibility for verification when algorithmic models assume epistemic authority.

### The Preservation-Transformation Tension

These debates reveal a core tension between two visions of epistemic agency with AI. The preservation view holds that epistemic agency requires maintaining human autonomy over belief formation, with AI serving only as tool or evidence-provider. The transformation view suggests that epistemic agency in sociotechnical environments may legitimately involve distributed, shared, or extended forms of cognitive authority where AI plays constitutive rather than merely instrumental roles.

This tension remains unresolved in current literature, with significant consequences for assessing when AI-prompted belief revision counts as rational persuasion (engaging autonomous epistemic capacities) versus epistemic displacement (substituting AI authority for human reasoning). As we will see, this ambiguity extends to democratic contexts where the nature of epistemic agency directly implicates political agency and citizenship.

---

**Word Count**: 823 words
