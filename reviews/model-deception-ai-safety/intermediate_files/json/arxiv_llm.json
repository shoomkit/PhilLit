{
  "status": "success",
  "source": "arxiv",
  "query": "all:language model representations AND cat:cs.AI",
  "results": [
    {
      "arxiv_id": "2601.09708",
      "title": "Fast-ThinkAct: Efficient Vision-Language-Action Reasoning via Verbalizable Latent Planning",
      "authors": [
        "Chi-Pin Huang",
        "Yunze Man",
        "Zhiding Yu",
        "Min-Hung Chen",
        "Jan Kautz",
        "Yu-Chiang Frank Wang",
        "Fu-En Yang"
      ],
      "abstract": "Vision-Language-Action (VLA) tasks require reasoning over complex visual scenes and executing adaptive actions in dynamic environments. While recent studies on reasoning VLAs show that explicit chain-of-thought (CoT) can improve generalization, they suffer from high inference latency due to lengthy reasoning traces. We propose Fast-ThinkAct, an efficient reasoning framework that achieves compact yet performant planning through verbalizable latent reasoning. Fast-ThinkAct learns to reason efficiently with latent CoTs by distilling from a teacher, driven by a preference-guided objective to align manipulation trajectories that transfers both linguistic and visual planning capabilities for embodied control. This enables reasoning-enhanced policy learning that effectively connects compact reasoning to action execution. Extensive experiments across diverse embodied manipulation and reasoning benchmarks demonstrate that Fast-ThinkAct achieves strong performance with up to 89.3\\% reduced inference latency over state-of-the-art reasoning VLAs, while maintaining effective long-horizon planning, few-shot adaptation, and failure recovery.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09708v1",
      "url": "https://arxiv.org/abs/2601.09708"
    },
    {
      "arxiv_id": "2601.09706",
      "title": "Value-Aware Numerical Representations for Transformer Language Models",
      "authors": [
        "Andreea Dutulescu",
        "Stefan Ruseti",
        "Mihai Dascalu"
      ],
      "abstract": "Transformer-based language models often achieve strong results on mathematical reasoning benchmarks while remaining fragile on basic numerical understanding and arithmetic operations. A central limitation is that numbers are processed as symbolic tokens whose embeddings do not explicitly encode numerical value, leading to systematic errors. We introduce a value-aware numerical representation that augments standard tokenized inputs with a dedicated prefix token whose embedding is explicitly conditioned on the underlying numerical value. This mechanism injects magnitude information directly into the model's input space while remaining compatible with existing tokenizers and decoder-only Transformer architectures. Evaluation on arithmetic tasks shows that the proposed approach outperforms baselines across numerical formats, tasks, and operand lengths. These results indicate that explicitly encoding numerical value is an effective and efficient way to improve fundamental numerical robustness in language models.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09706v1",
      "url": "https://arxiv.org/abs/2601.09706"
    },
    {
      "arxiv_id": "2601.09705",
      "title": "Revisiting Jahn--Teller Transitions in Correlated Oxides with Monte Carlo Modeling",
      "authors": [
        "Liam A. V. Nagle-Cocco",
        "Andrew L. Goodwin",
        "Clare P. Grey",
        "Si\u00e2n E. Dutton"
      ],
      "abstract": "Jahn--Teller (JT) distortions are a key driver of physical properties in many correlated oxide materials. Cooperative JT distortions, in which long-range orbital order reduces the symmetry of the average structure macroscopically, are common in JT-distorted materials at low temperatures. This long-range order will often melt on heating, \\textit{via} a transition to a high-temperature state without long-range orbital order. The nature of this transition has been observed to vary with different materials depending on crystal structure; in LaMnO$_3$ the transition has generally been interpreted as order-disorder, whereas in layered nickelates $A$NiO$_2$ ($A$=Li,Na) there is a displacive transition. Alternatively, recent theoretical work has suggested that previous attributions of order-disorder may in fact be a consequence of phonon anharmonicity, rather than persistence of JT distortions, which would suggest that the displacive transition may be more common than currently believed. In this work, we run Monte Carlo simulations with a simple Hamiltonian which is modified to include terms dependent on the JT amplitude $\u03c1$, which is allowed to vary within the simulation \\textit{via} the Metropolis algorithm. Our simulations yield distributions of JT amplitudes consistent with displacive rather than order-disorder behaviour for both perovskites and layered nickelates, suggesting that displacive-like JT transitions may be more common than previously assumed in both perovskites and layered nickelates. We also find significant differences between the transition observed for perovskites compared with layered nickelates, which we attribute to differing extensivity of configurational entropy on the two lattices, showing the crucial role of lattice geometry in determining behaviour.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cond-mat.str-el",
      "categories": [
        "cond-mat.str-el",
        "cond-mat.mtrl-sci",
        "cond-mat.stat-mech"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09705v1",
      "url": "https://arxiv.org/abs/2601.09705"
    },
    {
      "arxiv_id": "2601.09703",
      "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation",
      "authors": [
        "Sicong Liu",
        "Yanxian Huang",
        "Mingwei Liu",
        "Jiachi Chen",
        "Ensheng Shi",
        "Yuchi Ma",
        "Hongyu Zhang",
        "Yin Zhang",
        "Yanlin Wang"
      ],
      "abstract": "Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench, a corpus of validated tuples of original code and simplified code with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09703v1",
      "url": "https://arxiv.org/abs/2601.09703"
    },
    {
      "arxiv_id": "2601.09701",
      "title": "Evaluating GAN-LSTM for Smart Meter Anomaly Detection in Power Systems",
      "authors": [
        "Fahimeh Orvati Nia",
        "Shima Salehi",
        "Joshua Peeples"
      ],
      "abstract": "Advanced metering infrastructure (AMI) provides high-resolution electricity consumption data that can enhance monitoring, diagnosis, and decision making in modern power distribution systems. Detecting anomalies in these time-series measurements is challenging due to nonlinear, nonstationary, and multi-scale temporal behavior across diverse building types and operating conditions. This work presents a systematic, power-system-oriented evaluation of a GAN-LSTM framework for smart meter anomaly detection using the Large-scale Energy Anomaly Detection (LEAD) dataset, which contains one year of hourly measurements from 406 buildings. The proposed pipeline applies consistent preprocessing, temporal windowing, and threshold selection across all methods, and compares the GAN-LSTM approach against six widely used baselines, including statistical, kernel-based, reconstruction-based, and GAN-based models. Experimental results demonstrate that the GAN-LSTM significantly improves detection performance, achieving an F1-score of 0.89. These findings highlight the potential of adversarial temporal modeling as a practical tool for supporting asset monitoring, non-technical loss detection, and situational awareness in real-world power distribution networks. The code for this work is publicly available",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "eess.SP",
      "categories": [
        "eess.SP"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09701v1",
      "url": "https://arxiv.org/abs/2601.09701"
    },
    {
      "arxiv_id": "2601.09698",
      "title": "COMPOSE: Hypergraph Cover Optimization for Multi-view 3D Human Pose Estimation",
      "authors": [
        "Tony Danjun Wang",
        "Tolga Birdal",
        "Nassir Navab",
        "Lennart Bastian"
      ],
      "abstract": "3D pose estimation from sparse multi-views is a critical task for numerous applications, including action recognition, sports analysis, and human-robot interaction. Optimization-based methods typically follow a two-stage pipeline, first detecting 2D keypoints in each view and then associating these detections across views to triangulate the 3D pose. Existing methods rely on mere pairwise associations to model this correspondence problem, treating global consistency between views (i.e., cycle consistency) as a soft constraint. Yet, reconciling these constraints for multiple views becomes brittle when spurious associations propagate errors. We thus propose COMPOSE, a novel framework that formulates multi-view pose correspondence matching as a hypergraph partitioning problem rather than through pairwise association. While the complexity of the resulting integer linear program grows exponentially in theory, we introduce an efficient geometric pruning strategy to substantially reduce the search space. COMPOSE achieves improvements of up to 23% in average precision over previous optimization-based methods and up to 11% over self-supervised end-to-end learned methods, offering a promising solution to a widely studied problem.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09698v1",
      "url": "https://arxiv.org/abs/2601.09698"
    },
    {
      "arxiv_id": "2601.09697",
      "title": "Efficient Camera-Controlled Video Generation of Static Scenes via Sparse Diffusion and 3D Rendering",
      "authors": [
        "Jieying Chen",
        "Jeffrey Hu",
        "Joan Lasenby",
        "Ayush Tewari"
      ],
      "abstract": "Modern video generative models based on diffusion models can produce very realistic clips, but they are computationally inefficient, often requiring minutes of GPU time for just a few seconds of video. This inefficiency poses a critical barrier to deploying generative video in applications that require real-time interactions, such as embodied AI and VR/AR. This paper explores a new strategy for camera-conditioned video generation of static scenes: using diffusion-based generative models to generate a sparse set of keyframes, and then synthesizing the full video through 3D reconstruction and rendering. By lifting keyframes into a 3D representation and rendering intermediate views, our approach amortizes the generation cost across hundreds of frames while enforcing geometric consistency. We further introduce a model that predicts the optimal number of keyframes for a given camera trajectory, allowing the system to adaptively allocate computation. Our final method, SRENDER, uses very sparse keyframes for simple trajectories and denser ones for complex camera motion. This results in video generation that is more than 40 times faster than the diffusion-based baseline in generating 20 seconds of video, while maintaining high visual fidelity and temporal stability, offering a practical path toward efficient and controllable video synthesis.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09697v1",
      "url": "https://arxiv.org/abs/2601.09697"
    },
    {
      "arxiv_id": "2601.09696",
      "title": "Empathy Applicability Modeling for General Health Queries",
      "authors": [
        "Shan Randhawa",
        "Agha Ali Raza",
        "Kentaro Toyama",
        "Julie Hui",
        "Mustafa Naseem"
      ],
      "abstract": "LLMs are increasingly being integrated into clinical workflows, yet they often lack clinical empathy, an essential aspect of effective doctor-patient communication. Existing NLP frameworks focus on reactively labeling empathy in doctors' responses but offer limited support for anticipatory modeling of empathy needs, especially in general health queries. We introduce the Empathy Applicability Framework (EAF), a theory-driven approach that classifies patient queries in terms of the applicability of emotional reactions and interpretations, based on clinical, contextual, and linguistic cues. We release a benchmark of real patient queries, dual-annotated by Humans and GPT-4o. In the subset with human consensus, we also observe substantial human-GPT alignment. To validate EAF, we train classifiers on human-labeled and GPT-only annotations to predict empathy applicability, achieving strong performance and outperforming the heuristic and zero-shot LLM baselines. Error analysis highlights persistent challenges: implicit distress, clinical-severity ambiguity, and contextual hardship, underscoring the need for multi-annotator modeling, clinician-in-the-loop calibration, and culturally diverse annotation. EAF provides a framework for identifying empathy needs before response generation, establishes a benchmark for anticipatory empathy modeling, and enables supporting empathetic communication in asynchronous healthcare.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09696v1",
      "url": "https://arxiv.org/abs/2601.09696"
    },
    {
      "arxiv_id": "2601.09695",
      "title": "How well LLM-based test generation techniques perform with newer LLM versions?",
      "authors": [
        "Michael Konstantinou",
        "Renzo Degiovanni",
        "Mike Papadakis"
      ],
      "abstract": "The rapid evolution of Large Language Models (LLMs) has strongly impacted software engineering, leading to a growing number of studies on automated unit test generation. However, the standalone use of LLMs without post-processing has proven insufficient, often producing tests that fail to compile or achieve high coverage. Several techniques have been proposed to address these issues, reporting improvements in test compilation and coverage. While important, LLM-based test generation techniques have been evaluated against relatively weak baselines (for todays' standards), i.e., old LLM versions and relatively weak prompts, which may exacerbate the performance contribution of the approaches. In other words, stronger (newer) LLMs may obviate any advantage these techniques bring. We investigate this issue by replicating four state-of-the-art LLM-based test generation tools, HITS, SymPrompt, TestSpark, and CoverUp that include engineering components aimed at guiding the test generation process through compilation and execution feedback, and evaluate their relative effectiveness and efficiency over a plain LLM test generation method. We integrate current LLM versions in all approaches and run an experiment on 393 classes and 3,657 methods. Our results show that the plain LLM approach can outperform previous state-of-the-art approaches in all test effectiveness metrics we used: line coverage (by 17.72%), branch coverage (by 19.80%) and mutation score (by 20.92%), and it does so at a comparable cost (LLM queries). We also observe that the granularity at which the plain LLM is applied has a significant impact on the cost. We therefore propose targeting first the program classes, where test generation is more efficient, and then the uncovered methods to reduce the number of LLM requests. This strategy achieves comparable (slightly higher) effectiveness while requiring about 20% fewer LLM requests.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.SE",
      "categories": [
        "cs.SE"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09695v1",
      "url": "https://arxiv.org/abs/2601.09695"
    },
    {
      "arxiv_id": "2601.09694",
      "title": "LLMs can Compress LLMs: Adaptive Pruning by Agents",
      "authors": [
        "Sai Varun Kodathala",
        "Rakesh Vunnam"
      ],
      "abstract": "As Large Language Models (LLMs) continue to scale, post-training pruning has emerged as a promising approach to reduce computational costs while preserving performance. Existing methods such as SparseGPT and Wanda achieve high sparsity through layer-wise weight reconstruction or activation-aware magnitude pruning, but rely on uniform or hand-crafted heuristics to determine per-layer sparsity ratios. Moreover, recent work has shown that pruned LLMs suffer from severe factual knowledge degradation, with structured pruning methods experiencing near-total collapse in factual question-answering capabilities. We introduce agent-guided pruning, where a foundation model acts as an adaptive pruning agent to intelligently select which layers to prune at each iteration while preserving critical knowledge pathways. Our method constructs layer-wise sensitivity profiles by combining Wanda-inspired weight-activation metrics with gradient importance scores, normalized as z-scores for model-agnostic comparison. These statistics are processed by an LLM agent equipped with self-reflection capabilities, enabling it to learn from previous pruning outcomes and iteratively refine its strategy. A checkpoint rollback mechanism maintains model quality by reverting when perplexity degradation exceeds a threshold. We evaluate our approach on Qwen3 models (4B and 8B parameters) at approximately 45% sparsity, demonstrating substantial improvements over structured pruning baselines: 56% relative improvement in MMLU accuracy, 19x better factual knowledge retention on FreebaseQA, and 69% lower perplexity degradation. Notably, our framework requires no retraining, operates in a model-agnostic manner, and exhibits effective self-correction with only 2-4 rollbacks across 21-40 iterations, demonstrating that foundation models can effectively guide the compression of other foundation models.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09694v1",
      "url": "https://arxiv.org/abs/2601.09694"
    },
    {
      "arxiv_id": "2601.09693",
      "title": "Contrastive Geometric Learning Unlocks Unified Structure- and Ligand-Based Drug Design",
      "authors": [
        "Lisa Schneckenreiter",
        "Sohvi Luukkonen",
        "Lukas Friedrich",
        "Daniel Kuhn",
        "G\u00fcnter Klambauer"
      ],
      "abstract": "Structure-based and ligand-based computational drug design have traditionally relied on disjoint data sources and modeling assumptions, limiting their joint use at scale. In this work, we introduce Contrastive Geometric Learning for Unified Computational Drug Design (ConGLUDe), a single contrastive geometric model that unifies structure- and ligand-based training. ConGLUDe couples a geometric protein encoder that produces whole-protein representations and implicit embeddings of predicted binding sites with a fast ligand encoder, removing the need for pre-defined pockets. By aligning ligands with both global protein representations and multiple candidate binding sites through contrastive learning, ConGLUDe supports ligand-conditioned pocket prediction in addition to virtual screening and target fishing, while being trained jointly on protein-ligand complexes and large-scale bioactivity data. Across diverse benchmarks, ConGLUDe achieves state-of-the-art zero-shot virtual screening performance in settings where no binding pocket information is provided as input, substantially outperforms existing methods on a challenging target fishing task, and demonstrates competitive ligand-conditioned pocket selection. These results highlight the advantages of unified structure-ligand training and position ConGLUDe as a step toward general-purpose foundation models for drug discovery.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09693v1",
      "url": "https://arxiv.org/abs/2601.09693"
    },
    {
      "arxiv_id": "2601.09692",
      "title": "Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection",
      "authors": [
        "Tianyi Niu",
        "Justin Chih-Yao Chen",
        "Genta Indra Winata",
        "Shi-Xiong Zhang",
        "Supriyo Chakraborty",
        "Sambit Sahu",
        "Yue Zhang",
        "Elias Stengel-Eskin",
        "Mohit Bansal"
      ],
      "abstract": "Large Language Model (LLM) routers dynamically select optimal models for given inputs. Existing approaches typically assume access to ground-truth labeled data, which is often unavailable in practice, especially when user request distributions are heterogeneous and unknown. We introduce Routing with Generated Data (RGD), a challenging setting in which routers are trained exclusively on generated queries and answers produced from high-level task descriptions by generator LLMs. We evaluate query-answer routers (using both queries and labels) and query-only routers across four diverse benchmarks and 12 models, finding that query-answer routers degrade faster than query-only routers as generator quality decreases. Our analysis reveals two crucial characteristics of effective generators: they must accurately respond to their own questions, and their questions must produce sufficient performance differentiation among the model pool. We then show how filtering for these characteristics can improve the quality of generated data. We further propose CASCAL, a novel query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming the best query-answer router by 4.6% absolute accuracy when trained on weak generator data.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09692v1",
      "url": "https://arxiv.org/abs/2601.09692"
    },
    {
      "arxiv_id": "2601.09688",
      "title": "DeepResearchEval: An Automated Framework for Deep Research Task Construction and Agentic Evaluation",
      "authors": [
        "Yibo Wang",
        "Lei Wang",
        "Yue Deng",
        "Keming Wu",
        "Yao Xiao",
        "Huanjin Yao",
        "Liwei Kang",
        "Hai Ye",
        "Yongcheng Jing",
        "Lidong Bing"
      ],
      "abstract": "Deep research systems are widely used for multi-step web research, analysis, and cross-source synthesis, yet their evaluation remains challenging. Existing benchmarks often require annotation-intensive task construction, rely on static evaluation dimensions, or fail to reliably verify facts when citations are missing. To bridge these gaps, we introduce DeepResearchEval, an automated framework for deep research task construction and agentic evaluation. For task construction, we propose a persona-driven pipeline generating realistic, complex research tasks anchored in diverse user profiles, applying a two-stage filter Task Qualification and Search Necessity to retain only tasks requiring multi-source evidence integration and external retrieval. For evaluation, we propose an agentic pipeline with two components: an Adaptive Point-wise Quality Evaluation that dynamically derives task-specific evaluation dimensions, criteria, and weights conditioned on each generated task, and an Active Fact-Checking that autonomously extracts and verifies report statements via web search, even when citations are missing.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CL",
      "categories": [
        "cs.CL"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09688v1",
      "url": "https://arxiv.org/abs/2601.09688"
    },
    {
      "arxiv_id": "2601.09686",
      "title": "LARGE: A Locally Adaptive Regularization Approach for Estimating Gaussian Graphical Models",
      "authors": [
        "Ha Nguyen",
        "Sumanta Basu"
      ],
      "abstract": "The graphical Lasso (GLASSO) is a widely used algorithm for learning high-dimensional undirected Gaussian graphical models (GGM). Given i.i.d. observations from a multivariate normal distribution, GLASSO estimates the precision matrix by maximizing the log-likelihood with an \\ell_1-penalty on the off-diagonal entries. However, selecting an optimal regularization parameter \u03bbin this unsupervised setting remains a significant challenge. A well-known issue is that existing methods, such as out-of-sample likelihood maximization, select a single global \u03bband do not account for heterogeneity in variable scaling or partial variances. Standardizing the data to unit variances, although a common workaround, has been shown to negatively affect graph recovery. Addressing the problem of nodewise adaptive tuning in graph estimation is crucial for applications like computational neuroscience, where brain networks are constructed from highly heterogeneous, region-specific fMRI data.   In this work, we develop Locally Adaptive Regularization for Graph Estimation (LARGE), an approach to adaptively learn nodewise tuning parameters to improve graph estimation and selection. In each block coordinate descent step of GLASSO, we augment the nodewise Lasso regression to jointly estimate the regression coefficients and error variance, which in turn guides the adaptive learning of nodewise penalties. In simulations, LARGE consistently outperforms benchmark methods in graph recovery, demonstrates greater stability across replications, and achieves the best estimation accuracy in the most difficult simulation settings. We demonstrate the practical utility of our method by estimating brain functional connectivity from a real fMRI data set.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "stat.ME",
      "categories": [
        "stat.ME",
        "stat.CO",
        "stat.ML"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09686v1",
      "url": "https://arxiv.org/abs/2601.09686"
    },
    {
      "arxiv_id": "2601.09684",
      "title": "Disentangling Task Conflicts in Multi-Task LoRA via Orthogonal Gradient Projection",
      "authors": [
        "Ziyu Yang",
        "Guibin Chen",
        "Yuxin Yang",
        "Aoxiong Zeng",
        "Xiangquan Yang"
      ],
      "abstract": "Multi-Task Learning (MTL) combined with Low-Rank Adaptation (LoRA) has emerged as a promising direction for parameter-efficient deployment of Large Language Models (LLMs). By sharing a single adapter across multiple tasks, one can significantly reduce storage overhead. However, this approach suffers from negative transfer, where conflicting gradient updates from distinct tasks degrade the performance of individual tasks compared to single-task fine-tuning. This problem is exacerbated in LoRA due to the low-rank constraint, which limits the optimization landscape's capacity to accommodate diverse task requirements. In this paper, we propose Ortho-LoRA, a gradient projection method specifically tailored for the bipartite structure of LoRA. Ortho-LoRA dynamically projects conflicting task gradients onto the orthogonal complement of each other within the intrinsic LoRA subspace. Extensive experiments on the GLUE benchmark demonstrate that Ortho-LoRA effectively mitigates task interference, outperforming standard joint training and recovering 95\\% of the performance gap between multi-task and single-task baselines with negligible computational overhead.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.LG",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09684v1",
      "url": "https://arxiv.org/abs/2601.09684"
    },
    {
      "arxiv_id": "2601.09683",
      "title": "Controlling thermal conductivity in harmonic chains with correlated mass and bond disorder: Analytical approach",
      "authors": [
        "I. F. Herrera-Gonz\u00e1lez"
      ],
      "abstract": "We investigate heat transport in one-dimensional harmonic chains with mass disorder and weak bond disorder, coupled at both ends to oscillator heat baths through weak impedance mismatches. The model incorporates correlations in mass disorder, in bond disorder, and between the two. We find that the scaling of thermal conductivity $\u03ba$ with system size $N$ is determined solely by either mass disorder or bond disorder. This indicates that cross-correlations between the two types of disorder play no important role in the scaling behavior of $\u03ba$. Consequently, by tuning the self-correlations, it is possible to control how the thermal conductivity scales with the system size. Such control could have potential applications in thermoelectric devices and thermal insulation technologies.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cond-mat.stat-mech",
      "categories": [
        "cond-mat.stat-mech",
        "cond-mat.dis-nn"
      ],
      "doi": null,
      "journal_ref": "I. F. Herrera-Gonz\u00e1lez, Phys. Lett. A 563 (2025) 131044",
      "pdf_url": "https://arxiv.org/pdf/2601.09683v1",
      "url": "https://arxiv.org/abs/2601.09683"
    },
    {
      "arxiv_id": "2601.09682",
      "title": "Using 23 Years of ACS/SBC Data to Understand Backgrounds:Explaining & Predicting Background Variations",
      "authors": [
        "Christopher J. R. Clark",
        "Roberto J. Avila",
        "Alyssa Guzman",
        "Norman A. Grogin"
      ],
      "abstract": "Recent analysis of 23 years of Hubble Space Telescope ACS/SBC data has shown that background levels can vary considerably between observations, with most filters showing over an order of magnitude variation. For the shorter-wavelength filters, the background is understood to be dominated by airglow; however, what precisely drives background variations is not well constrained for any filter. Here, we explore the causes of the background variation. Using over 8,000 archival SBC observations, we developed a machine learning model that can accurately predict the background for an observation, based upon a set of 23 observational parameters. This model indicates that, depending on filter, the SBC background is generally dominated by Solar elevation, Solar separation angle, Earth limb angle of observation, SBC temperature, and target Galactic latitude.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "astro-ph.IM",
      "categories": [
        "astro-ph.IM"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09682v1",
      "url": "https://arxiv.org/abs/2601.09682"
    },
    {
      "arxiv_id": "2601.09680",
      "title": "Automating Supply Chain Disruption Monitoring via an Agentic AI Approach",
      "authors": [
        "Sara AlMahri",
        "Liming Xu",
        "Alexandra Brintrup"
      ],
      "abstract": "Modern supply chains are increasingly exposed to disruptions from geopolitical events, demand shocks, trade restrictions, to natural disasters. While many of these disruptions originate deep in the supply network, most companies still lack visibility beyond Tier-1 suppliers, leaving upstream vulnerabilities undetected until the impact cascades downstream. To overcome this blind-spot and move from reactive recovery to proactive resilience, we introduce a minimally supervised agentic AI framework that autonomously monitors, analyses, and responds to disruptions across extended supply networks. The architecture comprises seven specialised agents powered by large language models and deterministic tools that jointly detect disruption signals from unstructured news, map them to multi-tier supplier networks, evaluate exposure based on network structure, and recommend mitigations such as alternative sourcing options. \\rev{We evaluate the framework across 30 synthesised scenarios covering three automotive manufacturers and five disruption classes. The system achieves high accuracy across core tasks, with F1 scores between 0.962 and 0.991, and performs full end-to-end analyses in a mean of 3.83 minutes at a cost of \\$0.0836 per disruption. Relative to industry benchmarks of multi-day, analyst-driven assessments, this represents a reduction of more than three orders of magnitude in response time. A real-world case study of the 2022 Russia-Ukraine conflict further demonstrates operational applicability. This work establishes a foundational step toward building resilient, proactive, and autonomous supply chains capable of managing disruptions across deep-tier networks.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09680v1",
      "url": "https://arxiv.org/abs/2601.09680"
    },
    {
      "arxiv_id": "2601.09678",
      "title": "The impact of waveform systematics and Gaussian noise on the interpretation of GW231123",
      "authors": [
        "Sophie Bini",
        "Krzysztof Kr\u00f3l",
        "Katerina Chatziioannou",
        "Maximiliano Isi"
      ],
      "abstract": "GW231123 is an exceptional gravitational-wave event consistent with the merger of two massive, highly-spinning black holes. Reliable inference of the source properties is crucial for accurate interpretation of its astrophysical implications. However, characterization of GW231123 is challenging: only few signal cycles are observed and different signal models result in systematically different parameters. We investigate whether the interpretation of GW231123 is robust against model systematics and Gaussian detector noise. We show that the model systematics observed in GW231123 can be reproduced for a simulated signal based on the numerical-relativity surrogate model NRSur7dq4. Simulating data using the maximum-likelihood NRSur7dq4 waveform for GW231123 and no noise realization, we closely recover the systematics observed for the real signal. We then explore how the headline properties of GW231123 are impacted by Gaussian detector noise. Using the NRSur7dq4 maximum-likelihood waveform and different noise realizations, we consistently find support for large masses, high spin magnitudes (median $\u03c7_1\\geq 0.7$), and high spin precession (median $\u03c7_\\mathrm{p}\\geq 0.68$). The spin in the direction of the angular momentum ($\u03c7_\\mathrm{eff}$) fluctuates more. Finally, again comparing to simulated signals, we show that any differences in the GW231123 inference based on each separate detector are not statistically significant. These results show that the properties of GW231123, and most importantly the high mass and high spin magnitudes inferred by NRSur7dq4, are robust.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09678v1",
      "url": "https://arxiv.org/abs/2601.09678"
    },
    {
      "arxiv_id": "2601.09677",
      "title": "Bayesian Semi-Blind Deconvolution at Scale",
      "authors": [
        "Guillermina Senn",
        "H\u00e5kon Tjelmeland",
        "Nathan Glatt-Holtz",
        "Matt Walker",
        "Andrew Holbrook"
      ],
      "abstract": "Blind image deconvolution refers to the problem of simultaneously estimating the blur kernel and the true image from a set of observations when both the blur kernel and the true image are unknown. Sometimes, additional image and/or blur information is available and the term semi-blind deconvolution (SBD) is used. We consider a recently introduced Bayesian conjugate hierarchical model for SBD, formulated on an extended cyclic lattice to allow a computationally scalable Gibbs sampler. In this article, we extend this model to the general SBD problem, rewrite the previously proposed Gibbs sampler so that operations are performed in the Fourier domain whenever possible, and introduce a new marginal Hamiltonian Monte Carlo (HMC) blur update, obtained by analytically integrating the blur-image joint conditional over the image. The cyclic formulation combined with non-trivial linear algebra manipulations allows a Fourier-based, scalable HMC update, otherwise complicated by the rigid constraints of the SBD problem. Having determined the padding size in the cyclic embedding through a numerical experiment, we compare the mixing and exploration behaviour of the Gibbs and HMC blur updates on simulated data and on a real geophysical seismic imaging problem where we invert a grid with $300\\times50$ nodes, corresponding to a posterior with approximately $80,000$ parameters.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "stat.CO",
      "categories": [
        "stat.CO"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09677v1",
      "url": "https://arxiv.org/abs/2601.09677"
    },
    {
      "arxiv_id": "2601.09676",
      "title": "Static dc electric field orientation effects on two-photon Rydberg EIT",
      "authors": [
        "Rob Behary",
        "William Torg",
        "Mykhailo Vorobiov",
        "Nicolas DeStefano",
        "Adam Vernon",
        "Charles T. Fancher",
        "Neel Malvania",
        "Eugeniy E. Mikhailov",
        "Seth Aubin",
        "Irina Novikova"
      ],
      "abstract": "We examine the influence of a static dc electric field on Electromagnetically Induced Transparency (EIT) resonances that involve highly excited Rydberg states. Our focus is on how these resonances are altered when the relative orientation between the laser polarization and the external electric field vectors are varied. We experimentally demonstrate characteristic variations in the amplitude of the Stark-split EIT resonances, which can be explained by the selection rules in various geometries. We also present a simplified semi-analytical model that closely resembles the experimental observations. We use these findings to obtain information about the spatially inhomogeneous electric field, produced by a biased wire, using EIT fluorescence measurements that agrees with the expected angular dependencies. These results suggest that simultaneous analysis of frequency shifts and amplitudes of Rydberg EIT resonances may enable vector electrometry of electrostatic fields, necessary for many quantum sensing applications.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "physics.atom-ph",
      "categories": [
        "physics.atom-ph"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09676v1",
      "url": "https://arxiv.org/abs/2601.09676"
    },
    {
      "arxiv_id": "2601.09673",
      "title": "A probabilistic match classification model for sports tournaments",
      "authors": [
        "L\u00e1szl\u00f3 Csat\u00f3",
        "Andr\u00e1s Gyimesi"
      ],
      "abstract": "Existing match classification models in the tournament design literature have two major limitations: a contestant is considered indifferent only if uncertain future results do never affect its prize, and competitive matches are not distinguished with respect to the incentives of the contestants. We propose a probabilistic framework to address both issues. For each match, our approach relies on simulating all other matches played simultaneously or later to compute the qualifying probabilities under the three main outcomes (win, draw, loss), which allows the classification of each match into six different categories. The suggested model is applied to the previous group stage and the new incomplete round-robin league, introduced in the 2024/25 season of UEFA club competitions. An incomplete round-robin tournament is found to contain fewer stakeless matches where both contestants are indifferent, and substantially more matches where both contestants should play offensively. However, the robustly higher proportion of potentially collusive matches can threaten with serious scandals.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "physics.soc-ph",
      "categories": [
        "physics.soc-ph",
        "econ.GN",
        "math.OC",
        "stat.AP"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09673v1",
      "url": "https://arxiv.org/abs/2601.09673"
    },
    {
      "arxiv_id": "2601.09668",
      "title": "STEP3-VL-10B Technical Report",
      "authors": [
        "Ailin Huang",
        "Chengyuan Yao",
        "Chunrui Han",
        "Fanqi Wan",
        "Hangyu Guo",
        "Haoran Lv",
        "Hongyu Zhou",
        "Jia Wang",
        "Jian Zhou",
        "Jianjian Sun",
        "Jingcheng Hu",
        "Kangheng Lin",
        "Liang Zhao",
        "Mitt Huang",
        "Song Yuan",
        "Wenwen Qu",
        "Xiangfeng Wang",
        "Yanlin Lai",
        "Yingxiu Zhao",
        "Yinmin Zhang",
        "Yukang Shi",
        "Yuyang Chen",
        "Zejia Weng",
        "Ziyang Meng",
        "Ang Li",
        "Aobo Kong",
        "Bo Dong",
        "Changyi Wan",
        "David Wang",
        "Di Qi",
        "Dingming Li",
        "En Yu",
        "Guopeng Li",
        "Haiquan Yin",
        "Han Zhou",
        "Hanshan Zhang",
        "Haolong Yan",
        "Hebin Zhou",
        "Hongbo Peng",
        "Jiaran Zhang",
        "Jiashu Lv",
        "Jiayi Fu",
        "Jie Cheng",
        "Jie Zhou",
        "Jisheng Yin",
        "Jingjing Xie",
        "Jingwei Wu",
        "Jun Zhang",
        "Junfeng Liu",
        "Kaijun Tan",
        "Kaiwen Yan",
        "Liangyu Chen",
        "Lina Chen",
        "Mingliang Li",
        "Qian Zhao",
        "Quan Sun",
        "Shaoliang Pang",
        "Shengjie Fan",
        "Shijie Shang",
        "Siyuan Zhang",
        "Tianhao You",
        "Wei Ji",
        "Wuxun Xie",
        "Xiaobo Yang",
        "Xiaojie Hou",
        "Xiaoran Jiao",
        "Xiaoxiao Ren",
        "Xiangwen Kong",
        "Xin Huang",
        "Xin Wu",
        "Xing Chen",
        "Xinran Wang",
        "Xuelin Zhang",
        "Yana Wei",
        "Yang Li",
        "Yanming Xu",
        "Yeqing Shen",
        "Yuang Peng",
        "Yue Peng",
        "Yu Zhou",
        "Yusheng Li",
        "Yuxiang Yang",
        "Yuyang Zhang",
        "Zhe Xie",
        "Zhewei Huang",
        "Zhenyi Lu",
        "Zhimin Fan",
        "Zihui Cheng",
        "Daxin Jiang",
        "Qi Han",
        "Xiangyu Zhang",
        "Yibo Zhu",
        "Zheng Ge"
      ],
      "abstract": "We present STEP3-VL-10B, a lightweight open-source foundation model designed to redefine the trade-off between compact efficiency and frontier-level multimodal intelligence. STEP3-VL-10B is realized through two strategic shifts: first, a unified, fully unfrozen pre-training strategy on 1.2T multimodal tokens that integrates a language-aligned Perception Encoder with a Qwen3-8B decoder to establish intrinsic vision-language synergy; and second, a scaled post-training pipeline featuring over 1k iterations of reinforcement learning. Crucially, we implement Parallel Coordinated Reasoning (PaCoRe) to scale test-time compute, allocating resources to scalable perceptual reasoning that explores and synthesizes diverse visual hypotheses. Consequently, despite its compact 10B footprint, STEP3-VL-10B rivals or surpasses models 10$\\times$-20$\\times$ larger (e.g., GLM-4.6V-106B, Qwen3-VL-235B) and top-tier proprietary flagships like Gemini 2.5 Pro and Seed-1.5-VL. Delivering best-in-class performance, it records 92.2% on MMBench and 80.11% on MMMU, while excelling in complex reasoning with 94.43% on AIME2025 and 75.95% on MathVision. We release the full model suite to provide the community with a powerful, efficient, and reproducible baseline.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09668v1",
      "url": "https://arxiv.org/abs/2601.09668"
    },
    {
      "arxiv_id": "2601.09667",
      "title": "Collaborative Multi-Agent Test-Time Reinforcement Learning for Reasoning",
      "authors": [
        "Zhiyuan Hu",
        "Yunhai Hu",
        "Juncheng Liu",
        "Shuyue Stella Li",
        "Yucheng Wang",
        "Zhen Xu",
        "See-Kiong Ng",
        "Anh Tuan Luu",
        "Xinxing Xu",
        "Bryan Hooi",
        "Cynthia Breazeal",
        "Hae Won Park"
      ],
      "abstract": "Multi-agent systems have evolved into practical LLM-driven collaborators for many applications, gaining robustness from diversity and cross-checking. However, multi-agent RL (MARL) training is resource-intensive and unstable: co-adapting teammates induce non-stationarity, and rewards are often sparse and high-variance. Therefore, we introduce \\textbf{Multi-Agent Test-Time Reinforcement Learning (MATTRL)}, a framework that injects structured textual experience into multi-agent deliberation at inference time. MATTRL forms a multi-expert team of specialists for multi-turn discussions, retrieves and integrates test-time experiences, and reaches consensus for final decision-making. We also study credit assignment for constructing a turn-level experience pool, then reinjecting it into the dialogue. Across challenging benchmarks in medicine, math, and education, MATTRL improves accuracy by an average of 3.67\\% over a multi-agent baseline, and by 8.67\\% over comparable single-agent baselines. Ablation studies examine different credit-assignment schemes and provide a detailed comparison of how they affect training outcomes. MATTRL offers a stable, effective and efficient path to distribution-shift-robust multi-agent reasoning without tuning.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.AI",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09667v1",
      "url": "https://arxiv.org/abs/2601.09667"
    },
    {
      "arxiv_id": "2601.09664",
      "title": "Constant-roll $\u03b2$-exponential inflation: Palatini formalism",
      "authors": [
        "Ozan Sarg\u0131n"
      ],
      "abstract": "In this paper, we explore the inflationary dynamics of the $\u03b2$-exponential potential model, where a scalar field couples to quadratic $(R + R^2)$ gravity. In this model, the inflaton is the field that determines the size of the extra dimension. We employ the Palatini formalism to derive the resulting Einstein-frame generalized $k$-inflation effective theory, which we analyze under the assumption that the constant-roll condition is satisfied.   We scan the parameter space for inflationary predictions, specifically the spectral index $n_s$ and the tensor-to-scalar ratio $r$, ensuring consistency with the results from ACT DR6. The compliant regions are depicted accordingly. For a suitable range of the model parameters, the values obtained for the inflationary observables align with the most recent observations by the Atacama Cosmology Telescope (ACT) collaboration and/or the Planck mission.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "gr-qc",
      "categories": [
        "gr-qc",
        "astro-ph.CO",
        "hep-ph"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09664v1",
      "url": "https://arxiv.org/abs/2601.09664"
    },
    {
      "arxiv_id": "2601.09663",
      "title": "Self-Supervised Animal Identification for Long Videos",
      "authors": [
        "Xuyang Fang",
        "Sion Hannuna",
        "Edwin Simpson",
        "Neill Campbell"
      ],
      "abstract": "Identifying individual animals in long-duration videos is essential for behavioral ecology, wildlife monitoring, and livestock management. Traditional methods require extensive manual annotation, while existing self-supervised approaches are computationally demanding and ill-suited for long sequences due to memory constraints and temporal error propagation. We introduce a highly efficient, self-supervised method that reframes animal identification as a global clustering task rather than a sequential tracking problem. Our approach assumes a known, fixed number of individuals within a single video -- a common scenario in practice -- and requires only bounding box detections and the total count. By sampling pairs of frames, using a frozen pre-trained backbone, and employing a self-bootstrapping mechanism with the Hungarian algorithm for in-batch pseudo-label assignment, our method learns discriminative features without identity labels. We adapt a Binary Cross Entropy loss from vision-language models, enabling state-of-the-art accuracy ($>$97\\%) while consuming less than 1 GB of GPU memory per batch -- an order of magnitude less than standard contrastive methods. Evaluated on challenging real-world datasets (3D-POP pigeons and 8-calves feeding videos), our framework matches or surpasses supervised baselines trained on over 1,000 labeled frames, effectively removing the manual annotation bottleneck. This work enables practical, high-accuracy animal identification on consumer-grade hardware, with broad applicability in resource-constrained research settings. All code written for this paper are \\href{https://huggingface.co/datasets/tonyFang04/8-calves}{here}.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09663v1",
      "url": "https://arxiv.org/abs/2601.09663"
    },
    {
      "arxiv_id": "2601.09661",
      "title": "LiteEmbed: Adapting CLIP to Rare Classes",
      "authors": [
        "Aishwarya Agarwal",
        "Srikrishna Karanam",
        "Vineet Gandhi"
      ],
      "abstract": "Large-scale vision-language models such as CLIP achieve strong zero-shot recognition but struggle with classes that are rarely seen during pretraining, including newly emerging entities and culturally specific categories. We introduce LiteEmbed, a lightweight framework for few-shot personalization of CLIP that enables new classes to be added without retraining its encoders. LiteEmbed performs subspace-guided optimization of text embeddings within CLIP's vocabulary, leveraging a PCA-based decomposition that disentangles coarse semantic directions from fine-grained variations. Two complementary objectives, coarse alignment and fine separation, jointly preserve global semantic consistency while enhancing discriminability among visually similar classes. Once optimized, the embeddings are plug-and-play, seamlessly substituting CLIP's original text features across classification, retrieval, segmentation, and detection tasks. Extensive experiments demonstrate substantial gains over prior methods, establishing LiteEmbed as an effective approach for adapting CLIP to underrepresented, rare, or unseen classes.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09661v1",
      "url": "https://arxiv.org/abs/2601.09661"
    },
    {
      "arxiv_id": "2601.09660",
      "title": "Constitutive parameter inference using physics-based data-driven modeling in full volume datasets of intact and torn rotator cuff tendons",
      "authors": [
        "Carla Nathaly Villac\u00eds N\u00fa\u00f1ez",
        "Siddhartha Srivastava",
        "Ulrich Scheven",
        "Asheesh Bedi",
        "Krishna Garikipati",
        "Ellen M. Arruda"
      ],
      "abstract": "In this work, we characterized the material properties of an animal model of the rotator cuff tendon using full volume datasets of both its intact and injured states by capturing internal strain behavior throughout the tendon. Our experimental setup, involving tension along the fiber direction, activated volumetric, tensile, and shear mechanisms due to the tendon's complex geometry. We implemented an approach to model inference that we refer to as variational system identification (VSI) to solve the weak form of the stress equilibrium equation using these full volume displacements. Three constitutive models were used for parameter inference: a neo-Hookean model, a modified Holzapfel-Gasser-Ogden (HGO) model with higher-order terms in the first and second invariants, and a reduced polynomial model consisting of terms based on the first, second, and fiber-related invariants. Inferred parameters were further refined using an adjoint-based partial differential equation (PDE)-constrained optimization framework. Our results show that the modified HGO model captures the tendon's deformation mechanisms with reasonable accuracy, while the neo-Hookean model fails to reproduce key internal features, particularly the shear behavior in the injured tendon. Surprisingly, the simplified polynomial model performed comparably to the modified HGO formulation using only three terms. These findings suggest that while current constitutive models do not fully replicate the complex internal mechanics of the tendon, they are capable of capturing key trends in both intact and damaged tissue, using a homogeneous modeling approach. Continued model development is needed to bridge this gap and enable clinical-grade, predictive simulations of tendon injury and repair.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "physics.bio-ph",
      "categories": [
        "physics.bio-ph",
        "q-bio.TO"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09660v1",
      "url": "https://arxiv.org/abs/2601.09660"
    },
    {
      "arxiv_id": "2601.09659",
      "title": "On the Kolmogorov Superposition Theorem and Regular Means",
      "authors": [
        "Miguel de Carvalho"
      ],
      "abstract": "While Kolmogorov's probability axioms are widely recognized, it is less well known that in an often-overlooked 1930 note, Kolmogorov proposed an axiomatic framework for a unifying concept of the mean -- referred to as regular means. This framework yields a well-defined functional form encompassing the arithmetic, geometric, and harmonic means, among others.   In this article, we uncover an elegant connection between two key results of Kolmogorov by showing that the class of regular means can be derived directly from the Kolmogorov superposition theorem. This connection is conceptually appealing and illustrates that the superposition theorem deserves wider recognition in Statistics -- not only because of its link to regular means as shown here, but also due to its influence on the development of neural models and its potential connections with other statistical frameworks. In addition, we establish a stability property of regular means, showing that they vary smoothly under small perturbations of the generator. Finally, we provide insights into a recent universal central limit theorem that applies to the broad class of regular means.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "math.ST",
      "categories": [
        "math.ST"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09659v1",
      "url": "https://arxiv.org/abs/2601.09659"
    },
    {
      "arxiv_id": "2601.09658",
      "title": "Image2Garment: Simulation-ready Garment Generation from a Single Image",
      "authors": [
        "Selim Emir Can",
        "Jan Ackermann",
        "Kiyohiro Nakayama",
        "Ruofan Liu",
        "Tong Wu",
        "Yang Zheng",
        "Hugo Bertiche",
        "Menglei Chai",
        "Thabo Beeler",
        "Gordon Wetzstein"
      ],
      "abstract": "Estimating physically accurate, simulation-ready garments from a single image is challenging due to the absence of image-to-physics datasets and the ill-posed nature of this problem. Prior methods either require multi-view capture and expensive differentiable simulation or predict only garment geometry without the material properties required for realistic simulation. We propose a feed-forward framework that sidesteps these limitations by first fine-tuning a vision-language model to infer material composition and fabric attributes from real images, and then training a lightweight predictor that maps these attributes to the corresponding physical fabric parameters using a small dataset of material-physics measurements. Our approach introduces two new datasets (FTAG and T2P) and delivers simulation-ready garments from a single image without iterative optimization. Experiments show that our estimator achieves superior accuracy in material composition estimation and fabric attribute prediction, and by passing them through our physics parameter estimator, we further achieve higher-fidelity simulations compared to state-of-the-art image-to-garment methods.",
      "published": "2026-01-14",
      "updated": "2026-01-14",
      "primary_category": "cs.CV",
      "categories": [
        "cs.CV"
      ],
      "doi": null,
      "journal_ref": null,
      "pdf_url": "https://arxiv.org/pdf/2601.09658v1",
      "url": "https://arxiv.org/abs/2601.09658"
    }
  ],
  "count": 30,
  "errors": []
}
