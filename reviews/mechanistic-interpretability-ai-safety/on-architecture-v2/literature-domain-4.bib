@comment{
====================================================================
DOMAIN: Philosophical Accounts of Mechanism
SEARCH_DATE: 2025-12-21
PAPERS_FOUND: 12 total (High: 8, Medium: 3, Low: 1)
SEARCH_SOURCES: SEP, PhilPapers, Semantic Scholar, OpenAlex
====================================================================

DOMAIN_OVERVIEW:
The "new mechanistic" philosophy emerged in the late 1990s and early 2000s,
spearheaded by Machamer, Darden, and Craver (2000), Glennan (1996, 2017), and
Bechtel and Richardson (1993/2010). This framework shifted philosophical focus
from laws and covering-law explanation to mechanisms as the basic units of
scientific explanation across the life sciences. A mechanism is characterized as
entities and activities organized to produce regular changes from start to finish
conditions. The framework emphasizes decomposition and localization strategies,
whereby complex phenomena are explained by identifying component parts, their
activities, and their spatiotemporal organization.

Central to mechanistic explanation is the concept of "levels of mechanisms"
(Craver 2007), which differ from traditional size-based or disciplinary levels.
Mechanistic levels are defined by constitutive part-whole relationships: lower-level
components constitute higher-level capacities when properly organized. This leads
to interlevel integration rather than reduction, with neuroscience being the
paradigmatic domain. The framework has been extended to address completeness norms
(Craver & Kaplan 2018), mathematical explanation (Brigandt et al.), and applications
to psychology and cognitive science.

Recent developments include applications to artificial neural networks and AI
interpretability (Zhong et al. 2023), debates over levels and emergence (Craver
2025), and metaphysical refinements (Krickel 2017, 2018). The framework remains
actively debated regarding its scope, metaphysical commitments, and relationship to
other forms of explanation.

RELEVANCE_TO_PROJECT:
This domain provides theoretical grounding for what counts as "mechanistic" in
mechanistic interpretability of AI systems. It offers conceptual tools for
understanding levels of organization (neurons, circuits, networks), part-whole
relationships in neural network architectures, and norms for adequate mechanistic
explanation. The philosophical framework helps clarify when interpretability efforts
genuinely provide mechanistic understanding versus superficial description, and
whether neural networks can be said to have mechanisms in the philosophical sense.

NOTABLE_GAPS:
While recent work (Zhong et al. 2023) applies mechanistic explanation to neural
networks, systematic philosophical analysis of AI/ML systems through the mechanistic
lens remains sparse. The relationship between learned representations in neural
networks and mechanistic levels needs deeper exploration. Questions about whether
artificial neural networks satisfy the organization and constitutive criteria for
mechanisms remain underexplored.

SYNTHESIS_GUIDANCE:
Begin with foundational accounts (Machamer et al. 2000, Glennan 1996, Craver 2007)
establishing the mechanistic framework and levels concept. Contrast with earlier
decomposition strategies (Bechtel & Richardson 1993/2010). Address levels debates
and recent refinements. Connect to AI/neural network applications last, showing both
promise and challenges in applying mechanistic explanation to artificial systems.

KEY_POSITIONS:
- MDC Framework (3 papers): Machamer-Darden-Craver account emphasizing entities,
  activities, and productive continuity
- Glennan's Account (2 papers): Mechanisms as complex systems with invariant,
  change-relating generalizations
- Levels of Mechanisms (4 papers): Constitutive part-whole hierarchies in
  mechanistic explanation
- Applications to AI (1 paper): Recent work applying mechanistic explanation to
  neural networks
====================================================================
}

@article{machamer2000thinking,
  author = {Machamer, Peter and Darden, Lindley and Craver, Carl F.},
  title = {Thinking about Mechanisms},
  journal = {Philosophy of Science},
  year = {2000},
  volume = {67},
  number = {1},
  pages = {1--25},
  doi = {10.1086/392759},
  note = {
  CORE ARGUMENT: Proposes mechanisms as the fundamental explanatory structure in biology and neuroscience, defining mechanisms as entities and activities organized to produce regular changes from start to finish conditions. Mechanisms exhibit productive continuity whereby stages are connected spatiotemporally such that earlier stages produce later stages. Argues this framework better captures scientific practice than covering-law models, emphasizing how-possibly and how-actually questions over why-necessarily questions.

  RELEVANCE: Foundational paper establishing the MDC account of mechanistic explanation that dominates contemporary philosophy of neuroscience and biology. Directly relevant to mechanistic interpretability as it provides conceptual apparatus for what counts as genuine mechanistic understanding. The emphasis on entities, activities, and organization maps naturally onto neural network components (neurons, activations, architectures), though application to artificial systems requires careful extension of the framework.

  POSITION: New mechanist framework (MDC account) - establishes mechanistic explanation as alternative to covering-law models.
  },
  keywords = {mechanisms, MDC-framework, mechanistic-explanation, High}
}

@book{craver2007explaining,
  author = {Craver, Carl F.},
  title = {Explaining the Brain: Mechanisms and the Mosaic Unity of Neuroscience},
  publisher = {Oxford University Press},
  address = {Oxford},
  year = {2007},
  doi = {10.1093/acprof:oso/9780199299317.001.0001},
  note = {
  CORE ARGUMENT: Develops comprehensive mechanistic account of explanation in neuroscience, introducing the concept of "levels of mechanisms" defined by constitutive part-whole relationships rather than size or disciplinary boundaries. Argues neuroscience achieves unity through interlevel integration via mechanisms, not reduction to physics. Provides mutual manipulability (MM) criterion for constitutive relevance: X's φ-ing is constitutively relevant to S's ψ-ing when interventions on X change ψ-ing and vice versa. Establishes norms for adequacy of mechanistic explanations.

  RELEVANCE: Central work for understanding levels of organization and mechanistic explanation criteria directly applicable to neural network interpretability. The MM criterion provides testable conditions for claims about component relevance in artificial neural networks. The levels-of-mechanisms framework offers conceptual resources for understanding hierarchical organization in deep networks. However, challenges arise when trying to identify genuine constitutive relationships versus mere correlations in learned representations.

  POSITION: New mechanist framework - develops levels of mechanisms and constitutive relevance criteria.
  },
  keywords = {mechanisms, levels-of-mechanisms, neuroscience, mutual-manipulability, High}
}

@article{glennan1996mechanisms,
  author = {Glennan, Stuart},
  title = {Mechanisms and the Nature of Causation},
  journal = {Erkenntnis},
  year = {1996},
  volume = {44},
  number = {1},
  pages = {49--71},
  doi = {10.1007/BF00172853},
  note = {
  CORE ARGUMENT: Defines mechanisms as complex systems that produce behavior by virtue of component parts interacting according to direct, invariant, change-relating generalizations. Argues this mechanistic account of causation applies to both singular and general causal claims, providing unified treatment. Mechanisms explain not via subsumption under laws but by exhibiting organized component interactions. Emphasizes that mechanisms need not involve deterministic laws, only stable patterns of interaction among parts.

  RELEVANCE: Early foundational paper providing alternative mechanistic framework to MDC account, emphasizing invariant generalizations governing component interactions. Relevant to AI interpretability insofar as learned weights/connections in neural networks might be understood as encoding invariant change-relating relationships. However, whether neural network components interact via genuine invariant generalizations or merely statistical patterns remains philosophically contentious.

  POSITION: New mechanist framework (Glennan's account) - mechanisms as complex systems with invariant generalizations.
  },
  keywords = {mechanisms, causation, Glennan, High}
}

@book{glennan2017newmechanical,
  author = {Glennan, Stuart},
  title = {The New Mechanical Philosophy},
  publisher = {Oxford University Press},
  address = {Oxford},
  year = {2017},
  doi = {10.1093/oso/9780198779711.001.0001},
  note = {
  CORE ARGUMENT: Comprehensive development of mechanistic philosophy, arguing mechanisms provide foundation for understanding causation, scientific explanation, and natural kinds across sciences. Refines earlier account to emphasize minimal mechanisms and recursive character of mechanistic hierarchies. Proposes mechanisms undergird scientific ontology more broadly than just explanation, addressing metaphysical questions about composition, emergence, and interlevel causation. Argues mechanistic framework applies beyond biology to physics, chemistry, and social sciences.

  RELEVANCE: Most comprehensive recent statement of mechanistic philosophy, explicitly addressing scope and metaphysical foundations relevant for extending framework to artificial systems. Provides resources for thinking about whether artificial neural networks can genuinely instantiate mechanisms or merely simulate mechanistic behavior. The recursive hierarchy concept and minimal mechanism criteria offer tools for evaluating interpretability claims about network components and their organization.

  POSITION: New mechanist framework (Glennan's refined account) - comprehensive mechanistic metaphysics and epistemology.
  },
  keywords = {mechanisms, Glennan, mechanical-philosophy, metaphysics, High}
}

@book{craver2013searchmechanisms,
  author = {Craver, Carl F. and Darden, Lindley},
  title = {In Search of Mechanisms: Discoveries across the Life Sciences},
  publisher = {University of Chicago Press},
  address = {Chicago},
  year = {2013},
  doi = {10.5860/choice.51-5580},
  note = {
  CORE ARGUMENT: Analyzes discovery practices in molecular biology, biochemistry, and neuroscience to show how scientists search for and construct mechanistic explanations. Identifies reasoning strategies including schema instantiation, forward and backward chaining, and modular subassembly used to discover mechanism components and organization. Argues mechanism discovery is iterative process moving from incomplete sketches to more adequate models through constraint satisfaction. Provides detailed case studies of protein synthesis, chemical transmission, and LTP mechanisms.

  RELEVANCE: Offers methodological insights for mechanistic interpretability research by showing how scientists actually discover and validate mechanisms. The reasoning strategies and iterative refinement process parallel practices in interpretability research where initial hypotheses about circuit functions are tested and revised. Schema instantiation strategy particularly relevant for using known computational motifs to guide interpretation of learned circuits. However, discovery context differs significantly given that neural networks are designed artifacts rather than naturally occurring systems.

  POSITION: New mechanist framework - discovery and methodology in mechanistic science.
  },
  keywords = {mechanisms, discovery, methodology, Craver-Darden, High}
}

@book{bechtel2010discovering,
  author = {Bechtel, William and Richardson, Robert C.},
  title = {Discovering Complexity: Decomposition and Localization as Strategies in Scientific Research},
  publisher = {MIT Press},
  address = {Cambridge, MA},
  year = {2010},
  edition = {2nd},
  doi = {10.7551/mitpress/8328.001.0001},
  note = {
  CORE ARGUMENT: Analyzes decomposition (dividing systems into parts) and localization (mapping functions to parts) as fundamental heuristic strategies in biological and cognitive science research. Shows when these strategies succeed and fail, introducing concepts of near-decomposability and distributed organization. Argues successful mechanistic explanation requires both structural decomposition and functional localization, but many biological systems resist simple decomposition due to nonlinear interactions and distributed processing. Second edition adds discussion of dynamic mechanistic explanation.

  RELEVANCE: Foundational for understanding decomposition strategies central to mechanistic interpretability. The analysis of when decomposition succeeds versus fails directly applicable to debates about whether neural networks can be decomposed into interpretable circuits versus being fundamentally distributed. Near-decomposability concept potentially useful for understanding modular versus holistic processing in deep networks. However, the book focuses on biological systems where functions are evolutionarily selected, whereas neural network functions are emergent from training.

  POSITION: New mechanist framework - decomposition and localization heuristics in mechanistic science.
  },
  keywords = {mechanisms, decomposition, localization, Bechtel-Richardson, High}
}

@incollection{glennan2017routledgehandbook,
  author = {Glennan, Stuart and Illari, Phyllis},
  title = {The Routledge Handbook of Mechanisms and Mechanical Philosophy},
  publisher = {Routledge},
  address = {London},
  year = {2017},
  doi = {10.4324/9781315731544},
  note = {
  CORE ARGUMENT: Comprehensive edited collection surveying mechanistic philosophy across domains including biology, neuroscience, chemistry, physics, and social science. Addresses core theoretical issues (characterizing mechanisms, levels, constitutive relevance, emergence), methodological questions (discovery, explanation, modeling), and domain-specific applications. Includes chapters on mechanistic explanation in computation, engineering, and medicine. Represents state-of-the-art in mechanistic philosophy circa 2017 with contributions from all major figures in the field.

  RELEVANCE: Essential reference for comprehensive understanding of mechanistic framework and its applications. Multiple chapters relevant to AI/neural network interpretability, particularly those on computation (Piccinini), levels (Craver & Povich), and mathematical modeling in mechanistic explanation (Brigandt). Provides diverse perspectives on contested issues useful for evaluating mechanistic interpretability claims. The breadth of domains covered helps assess whether neural networks are sufficiently similar to paradigm mechanistic systems.

  POSITION: New mechanist framework - comprehensive handbook covering theoretical and applied issues.
  },
  keywords = {mechanisms, handbook, comprehensive, Medium}
}

@article{wimsatt1994ontology,
  author = {Wimsatt, William C.},
  title = {The Ontology of Complex Systems: Levels of Organization, Perspectives, and Causal Thickets},
  journal = {Canadian Journal of Philosophy},
  year = {1994},
  volume = {20},
  pages = {207--274},
  doi = {10.1080/00455091.1994.10717400},
  note = {
  CORE ARGUMENT: Develops account of levels of organization as "local maxima of regularity and predictability" in complex systems, emphasizing perspectival and contextual character of levels. Argues levels are not metaphysically fundamental but emerge from evolved organization and our epistemic interests. Introduces concepts of causal thickets (dense causal interactions), perspective-relativity of levels, and robustness as criterion for level identification. Criticizes overly neat hierarchical pictures of nature, emphasizing messiness and context-dependence of real scientific practice.

  RELEVANCE: Provides alternative to Craver's mechanistic levels framework, emphasizing contextual and perspectival dimensions of level-identification relevant for interpretability research. The "local maxima" concept potentially useful for understanding why certain neural network decompositions yield more stable interpretations than others. Causal thicket concept applies to dense interconnections in deep networks. However, perspectival account may undermine claims about objective mechanistic structure in neural networks if levels are merely epistemic convenience.

  POSITION: Levels of organization - perspectival and contextual account emphasizing local maxima.
  },
  keywords = {levels, organization, Wimsatt, perspectival, High}
}

@incollection{wimsatt1976reductionism,
  author = {Wimsatt, William C.},
  title = {Reductionism, Levels of Organization, and the Mind-Body Problem},
  booktitle = {Consciousness and the Brain},
  publisher = {Springer},
  year = {1976},
  pages = {205--267},
  doi = {10.1007/978-1-4684-2196-5_9},
  note = {
  CORE ARGUMENT: Early influential paper analyzing levels of organization and reduction in biology and psychology. Argues levels are defined by compositional hierarchies but also by different modes of description and theoretical frameworks. Develops account of intertheoretic reduction as multilevel with successive approximations rather than simple derivation. Emphasizes functional organization and near-decomposability in defining levels. Critiques both eliminative reductionism and autonomous special sciences, advocating middle path of explanatory integration across levels.

  RELEVANCE: Historically important precursor to mechanistic levels framework, introducing many themes developed by later new mechanists. The functional organization and near-decomposability concepts applicable to neural network interpretability. However, this earlier work predates the constitutive relevance framework central to contemporary mechanistic philosophy, focusing more on intertheoretic reduction. Provides historical context for understanding evolution of levels concepts from traditional philosophy of science to new mechanism.

  POSITION: Levels of organization - early account emphasizing compositional hierarchy and functional organization.
  },
  keywords = {levels, organization, reduction, Wimsatt, Medium}
}

@article{craver2018moredetails,
  author = {Craver, Carl F. and Kaplan, David M.},
  title = {Are More Details Better? On the Norms of Completeness for Mechanistic Explanations},
  journal = {The British Journal for the Philosophy of Science},
  year = {2018},
  volume = {71},
  number = {1},
  pages = {287--319},
  doi = {10.1093/bjps/axy015},
  note = {
  CORE ARGUMENT: Addresses criticism that mechanistic accounts require complete detail about mechanisms, arguing instead that completeness is relative to explanatory purpose and contrast class. Distinguishes causal from constitutive explanation, each with different completeness norms. For constitutive explanation, relevance depends on whether components make difference to phenomenon being explained, not on level of detail. Abstracting away from irrelevant details often improves explanation by highlighting what matters. Defends mechanistic framework against charges of incompatibility with abstraction in scientific modeling.

  RELEVANCE: Directly relevant to mechanistic interpretability debates about level of detail required for adequate understanding. Provides norms for evaluating when interpretability research achieves sufficient mechanistic detail versus when more abstraction is warranted. The relevance-based rather than completeness-based criterion helps assess mechanistic interpretability claims: not all circuit details matter, only those making difference to target behavior. However, determining which details are relevant in neural networks may be more difficult than in biological systems.

  POSITION: New mechanist framework - norms of completeness and abstraction in mechanistic explanation.
  },
  keywords = {mechanisms, completeness, abstraction, Craver-Kaplan, High}
}

@article{zhong2023clock,
  author = {Zhong, Ziqian and Liu, Ziming and Tegmark, Max and Andreas, Jacob},
  title = {The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks},
  journal = {ArXiv},
  year = {2023},
  volume = {abs/2306.17844},
  doi = {10.48550/arXiv.2306.17844},
  arxivid = {2306.17844},
  note = {
  CORE ARGUMENT: Demonstrates that neural networks trained on same task (modular addition) can discover qualitatively different algorithmic implementations ("Clock" vs "Pizza" algorithms) depending on initialization and hyperparameters. Shows algorithm discovery in neural networks exhibits phase transitions with diverse solutions possible for single problem. Argues mechanistic interpretability must account for multiplicity of mechanistic implementations and develop tools for characterizing algorithmic phase space. Challenges assumption that trained networks converge to unique optimal mechanism.

  RELEVANCE: First major application of mechanistic explanation framework explicitly to neural network interpretability, demonstrating both promise and challenges. Shows neural networks can implement comprehensible mechanisms but that these mechanisms may be diverse and initialization-dependent. Raises fundamental question about whether mechanistic interpretability should identify the mechanism a network implements or merely mechanistic possibilities. The multiplicity finding suggests mechanistic understanding may require population-level analysis across training runs rather than individual network analysis.

  POSITION: Application of mechanistic explanation to neural networks - demonstrates algorithmic diversity and phase transitions.
  },
  keywords = {mechanisms, neural-networks, interpretability, algorithmic-diversity, High}
}

@article{craver2025defending,
  author = {Craver, Carl F.},
  title = {Defending Levels by Trading Waves for Trees},
  journal = {Synthese},
  year = {2025},
  volume = {205},
  doi = {10.1007/s11229-025-04967-y},
  note = {
  CORE ARGUMENT: Responds to recent criticisms of levels-of-mechanisms framework by refining account using tree-structured rather than wave-based metaphors for mechanistic hierarchies. Argues mechanistic levels are well-defined via constitutive part-whole relationships even when systems exhibit complex cross-level interactions. Defends levels concept against deflationary alternatives while acknowledging context-dependence and perspectival elements. Claims tree structure better captures branching, convergent, and nested relationships in mechanistic hierarchies than simple layered models.

  RELEVANCE: Most recent defense and refinement of mechanistic levels framework, addressing contemporary criticisms relevant for AI interpretability applications. The tree-structured hierarchy concept potentially useful for understanding complex mechanistic organization in neural networks with skip connections, attention mechanisms, and other non-sequential architectural features. Provides updated conceptual resources for evaluating whether neural networks exhibit genuine mechanistic levels versus merely superficial hierarchical organization.

  POSITION: New mechanist framework - refined defense of mechanistic levels concept.
  },
  keywords = {mechanisms, levels, Craver, recent, Low}
}
